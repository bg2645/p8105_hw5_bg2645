---
title: "p8105_hw5_bg2645"
author: "Bing Bing Guo"
date: "11/6/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(purrr)
library(broom)
```


## Problem 1 
```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```
* For numeric variables,replace "NA" with the mean of non-missing values. For character variables, replace "NA" with "virginica".
```{r} 
insert_new = function(x) {
  if(is.numeric(x) == TRUE) {
    x = x %>%
      replace_na(mean(x, na.rm = TRUE))
  }
  
else if(is.character(x) == TRUE){
  x = x %>%
    replace_na("virginica")
 }

return(x)

}

iris_with_missing = map_df(iris_with_missing,insert_new) 

iris_with_missing
```

## Problem 2 
* Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time
```{r} 
longstudy_files = list.files(path = "./data",full.names = TRUE) %>% 
  map(read.csv) %>% 
  reduce(rbind) %>% 
  janitor::clean_names() %>%
  mutate(subject_id = c(1:20), 
         arm = ifelse(subject_id == c(1:10), "control",
                     "experimental")) %>% 
  gather(key = week, value = observation, week_1:week_8) %>% 
  mutate(week = str_replace(week, "week_", ""))
longstudy_files
```
* Make a spaghetti plot showing observations on each subject over time
```{r}
longstudy_files %>% 
  ggplot(aes(x = week, y = observation)) + 
  geom_line(aes(group = subject_id, color = arm)) + 
   labs(
    title = "Observation For Subjects Over Time",
    x = "Week",
    y = "Observation",
    caption = "Data from a longitudinal study that included a control arm and an experimental arm"
   )
```

* Based on the graph, observation values for subjects in the experimental arm seemed to increase as the weeks progressed, though there were still slight fluctuations - but in general there was a positive upward trend. However, for participants in the control arm the observation values seemed to stay fairly constant, though with slight fluctuations, as the weeks progressed. 

## Problem 3 

Conduct a simulation to explore power in a simple linear regression 

* Create function and set design elements 

```{r}
set.seed(1)
sim_regression = function(n=30, beta0 = 2, beta1 = 0) {
  sim_data = tibble(
    x = rnorm(n, mean=0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt(50))
    )
  ls_fit = lm(y ~ x, data = sim_data) %>%
  broom::tidy()
  tibble( 
    beta1_hat = ls_fit[[2,2]],
    p_value=ls_fit[[2,5]]
    )
}
```
* Generate 10000 datasets from the model
```{r}
set.seed(1)

sim_results = rerun (10000, sim_regression(beta1 = 0)) %>% 
  bind_rows()

sim_results
```

* Repeat the above for beta1 ={1,2,3,4,5,6}

```{r}
  new_sim_results = 
  tibble(new_beta1 = c(0,1,2,3,4,5,6)) %>% 
  mutate(
    output_lists = map(.x = new_beta1, 
                       ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
new_sim_results
```

**Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of beta1 on the x axis.**

```{r} 
new_sim_results %>% 
  group_by(new_beta1) %>% 
  summarize(
    n = n(),
    power = sum(p_value < 0.05)/n) %>% 
ggplot(aes(x = new_beta1, y = power)) + 
  geom_smooth() + geom_point() + 
  labs(
    title = "Association Between Effect Size and Power",
    x = "True Value of Beta1",
    y = "Power of the Test"
   )
```

* Based on the plot above, it can be seen that as the true value of beta2 increases, the power of the test also increases. Thus,showing that when effect size increases the power of the test increases. 



**Make a plot showing the average estimate of beta1 on the y axis and the true value of beta1 on the x axis. Make a second plot (or overlay on the first) the average estimate of beta1 *only in samples* for which the null was rejected on the y axis and the true value of beta1 on the x axis.**
```{r}
true_val = new_sim_results %>%
group_by(new_beta1) %>% 
summarise(average_1 = mean(beta1_hat))

null_reject = new_sim_results %>%
filter (p_value < 0.05) %>% 
group_by(new_beta1) %>% 
summarize(average_2 = mean(beta1_hat))

ggplot(true_val, aes(x = new_beta1, y = average_1)) +
geom_line(aes(color = "Test 1"))  +
  geom_line(data = null_reject, aes(x= new_beta1, y = average_2, 
                                    color = "Test 2 (H0 rejected)")) +
  labs(
    color="Legend",
    title = "Association between Beta1_hat and the true value of Beta1",
    x = "True Value of Beta1",
    y = "Average Estimate of Beta1_hat"
   )
```

* Based on the two overlayed graphs in the figure above, it can be see that the sample average of beta1_hat across tests for which the null is rejected is not equal to the true value of beta1. This is because there is a large difference when the true value of beta 1 is small (eg. the difference is particularily apparent when the true value of beta1 is ~1-2), as the true value of beta1 increases the difference between the two tests becomes smaller. 


